<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" >

<title>梯度下降 | JIANG-HS</title>

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">

<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">
<link rel="shortcut icon" href="https://JIANG-HS.github.io/favicon.ico?v=1590059974264">
<link rel="stylesheet" href="https://JIANG-HS.github.io/styles/main.css">



<link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />
<script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"></script>



    <meta name="description" content="#简介
梯度下降法（gradient descent）是一个最优化算法，也称为最速下降法（steepest descent）。常用于机器学习和人工智能当中用来递归性地逼近最小偏差模型。

缺点：1.靠近极小值时收敛速度减慢。
2.直线搜索时..." />
    <meta name="keywords" content="" />
  </head>
  <body>
    <div id="app" class="main">

      <div class="sidebar" :class="{ 'full-height': menuVisible }">
  <div class="top-container" data-aos="fade-right">
    <div class="top-header-container">
      <a class="site-title-container" href="https://JIANG-HS.github.io">
        <img src="https://JIANG-HS.github.io/images/avatar.png?v=1590059974264" class="site-logo">
        <h1 class="site-title">JIANG-HS</h1>
      </a>
      <div class="menu-btn" @click="menuVisible = !menuVisible">
        <div class="line"></div>
      </div>
    </div>
    <div>
      
        
          <a href="/" class="site-nav">
            首页
          </a>
        
      
        
          <a href="/archives" class="site-nav">
            归档
          </a>
        
      
        
          <a href="/tags" class="site-nav">
            标签
          </a>
        
      
        
          <a href="/post/about" class="site-nav">
            关于
          </a>
        
      
    </div>
  </div>
  <div class="bottom-container" data-aos="flip-up" data-aos-offset="0">
    <div class="social-container">
      
        
      
        
      
        
      
        
      
        
      
    </div>
    <div class="site-description">
      温故而知新
    </div>
    <div class="site-footer">
      Powered by <a href="https://github.com/getgridea/gridea" target="_blank">Gridea</a> | <a class="rss" href="https://JIANG-HS.github.io/atom.xml" target="_blank">RSS</a>
    </div>
  </div>
</div>


      <div class="main-container">
        <div class="content-container" data-aos="fade-up">
          <div class="post-detail">
            <h2 class="post-title">梯度下降</h2>
            <div class="post-date">2020-05-21</div>
            
            <div class="post-content" v-pre>
              <p>#简介<br>
梯度下降法（gradient descent）是一个最优化算法，也称为最速下降法（steepest descent）。常用于机器学习和人工智能当中用来递归性地逼近最小偏差模型。<br>
<img src="D:%5Cphoto%22%E5%85%AC%E5%BC%8F%22" alt="alt" loading="lazy"></p>
<p>缺点：1.靠近极小值时收敛速度减慢。<br>
2.直线搜索时可能会产生一些问题。<br>
3.可能会“之字形”地下降。</p>
<figure data-type="image" tabindex="1"><img src="%E5%9B%BE%E7%89%87%E5%9C%B0%E5%9D%80" alt="alt" title="title" loading="lazy"></figure>
<h1 id=""></h1>
<p>#梯度下降法三兄弟（BGD，SGD，MBGD）<br>
##1.批量梯度下降法（Batch Gradient Descent）<br>
批量梯度下降法每次都使用所有的样本进行参数的更新，即<br>
L(w)=12NΣNi=1(fM(xi,w)−y)2<br>
##2.随机梯度下降法（Stochastic Gradient Descent）</p>
<p>##3.小批量梯度下降法（Mini-batch Gradient Descent）</p>

            </div>
            
            
              <div class="next-post">
                <div class="next">下一篇</div>
                <a href="https://JIANG-HS.github.io/post/belQdrZZ2/">
                  <h3 class="post-title">
                    Anaconda更新和Spyder更新的指令
                  </h3>
                </a>
              </div>
            

            

          </div>

        </div>
      </div>
    </div>

    <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
<script type="application/javascript">

AOS.init();

var app = new Vue({
  el: '#app',
  data: {
    menuVisible: false,
  },
})

</script>






  </body>
</html>
